{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; HealthCare Analysis Using Medicare Data</h1>\n",
    "\n",
    "\n",
    "<h3><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;By: The Data Squad (Jony M, Kevin B, Julio C, Rashmi A, Maitrai)</i></h3>\n",
    "\n",
    "# Part 1: Project Introduction\n",
    "<h4>An introduction that discusses the data you are analyzing, and the question or questions you are investigating.</h4> \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Our project idea is to derive inferences and insights related to healthcare methods and facilities in the US by analyzing medicare data collected over a period of time. The goal is to find whether better facilities/cheaper facilities/less manpower/more manpower will decrease/increase the charges incurred by patients. We will look to find a correlation between facilities(Nursing, pharmaceutical, etc.) and various charges incurred at the hospitals and how these insights pan out demographically. \n",
    "\n",
    "The data that our group will be utilizing <a href=\"https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data\">can be found here</a>.\n",
    "<h3><i>Hypothesis</i></h3>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The purposes of this notebook is to ponder the idea if more equipments lead to lesser number of staff required (such as nurses) in the hospital to manage mundane tasks; States with higher GDP will have lower number of inpatients and outpatients. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2: Potential Changes\n",
    "<h4>A discussion whether your scope has changed since the check-in\n",
    "proposal slides. What did you aim to do that you will not do and what have you added to the project?</h4>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This project's purpose is to perform an exploratory data analysis and find out the correlation between different features, especially the facilities, equipment and aggregated charges data. The scope of the project remains as the stated inside the project proposal. This means our data spans across hospitals in the country and over a period of 4 years(2012-2015). Insights can be studied demographically and geographically.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There have been minor to no deviance from our original proposal. This means that our plans to perform Data Cleaning, and Exploratory Data Analysis on hospital records is the primary focus. Instances of deviance occur when finding meaningless results from what we would hypothesis to be useful for conclusion drawing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 3: Data Cleaning\n",
    "<h4><center>Show clearly how you cleaned your data.</center></h4>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The data we have (<a href=\"https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data\">reference</a>) spans a few years with tons of classes, so there is a bit of refining needed. There are a few ways in which we cleaned our data. One of which is filtering out the classes in which we can obtain no valuable information from (missing data, vague implications, invaluable towards project scope, etc).\n",
    "\n",
    "Lets first start by importing neccessary libraries for visualizations later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The purposes of using Matplotlib (<a href=\"https://matplotlib.org/tutorials/introductory/pyplot.html\">reference</a>) is to enable basic plotting mechanisms for visualization of our data. Seaborn (<a href=\"https://seaborn.pydata.org/\">reference</a>) will be used similarly to matplotlib, although with specific functionality. Finally, pandas (<a href=\"https://pandas.pydata.org/\">reference</a>) will be used for data manipulation and extraction throughout the course of this notebook.\n",
    "\n",
    "The list of variables that we are to retain throughout the cleaning are as follows:\n",
    "\n",
    "##### Variables\n",
    "- Year\n",
    "    - Time of year\n",
    "- Reason\n",
    "    - Type 1\n",
    "    - Type 2\n",
    "    - Type 3\n",
    "- Type of patient   ----------------- TODO: FIX LIST TO SHOW CLASSES WE ARE FOCUSING ON\n",
    "    - Inpatient\n",
    "    - Outpatient\n",
    "- Spending\n",
    "- Distance\n",
    "    - Local\n",
    "    - Non-local\n",
    "- Care type\n",
    "    - General\n",
    "    - Transplant\n",
    "    - Donation\n",
    "    - Surgery\n",
    "- Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 4: Exploratory data analysis\n",
    "<h4> Explain what your data looks like. Include any interesting issues or preliminary conclusions you have about your data.</h4>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To start off, our data contains several thousand records on health care facilities. \n",
    "<p>The datasets provide state-wise home agencies and nursing facilities data which represents the beneficiaries cost, total stay days, claims allowed as well as beneficiary distribution based on gender and disease.  \n",
    "We have plotted graphs that showcase the no of facilities per state and compared nursing facilities count to home health agencies count per state.\n",
    "The dataset also provide the drugs supply and their cost as well as total claims. We have computed the state wise count of all the claims, nursing specialities associated with the highest claims.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 5: Visualizations\n",
    "<h4>Visualization with an explanation about why you thought this was an interesting hypothesis to investigate. \n",
    "</h4>\n",
    "<h4> Nursing Facilities per State</h4>\n",
    "<img src=\"EDA1.png\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 6: ML Analysis\n",
    "<h4>Visualization with an explanation about why you thought this was an interesting hypothesis to investigate. \n",
    "</h4>\n",
    "\n",
    "TODO: FILL OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'..\\\\data_files\\\\Inpatient_charges.csv' does not exist",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5d8ab9608a14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Load the inpatient dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0min_charges_path2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"..\\data_files\\Inpatient_charges.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0min_charges2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_charges_path2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_charges2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Average Total Payments'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'..\\\\data_files\\\\Inpatient_charges.csv' does not exist"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the inpatient dataset\n",
    "in_charges_path2 = \"..\\data_files\\Inpatient_charges.csv\"\n",
    "in_charges2 = pd.read_csv(in_charges_path2, skipinitialspace=True, low_memory=False, index_col=0)\n",
    "\n",
    "a = np.array(in_charges2['Average Total Payments'].tolist())\n",
    "\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(a)\n",
    "\n",
    "s = []\n",
    "for i in a:\n",
    "    s.append([i])\n",
    "    \n",
    "X = np.asarray(s)\n",
    "\n",
    "a2 = np.array(in_charges2['Average Covered Charges'].tolist())\n",
    "\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(a2)\n",
    "\n",
    "s2 = []\n",
    "for i in a2:\n",
    "    s2.append([i])\n",
    "    \n",
    "Y = np.asarray(s2)\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train = X[:-50]\n",
    "X_test = X[-50:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "y_train = Y[:-50]\n",
    "y_test = Y[-50:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel(\"Average Total Payments\")\n",
    "plt.ylabel(\"Average Covered Charges\")\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 7: Reflection\n",
    "\n",
    "##### A Discussion of the Following:\n",
    "- What is hardest part of the project that you’ve encountered so far?\n",
    "- What are your initial insights?\n",
    "- Are there any concrete results you can show at this point? If not, why not?\n",
    "- Going forward, what are the current biggest problems you’re facing?\n",
    "- Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?\n",
    "- Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?\n",
    "\n",
    "<h4>What is hardest part of the project that you’ve encountered so far? </h4>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;So far, the most challenging part of the project stems from the Exploratory Data Analysis cycle discussed earlier in the semester. Our group went through a few different approaches to clean out our data into something useful. Many of the classes within our dataset were typed oddly and needed to be convered into something python could handle. Once that step was completed, we often found ourselves lost in what we were trying to prove and methods to do so given the data files on hand which lead to more questions asked on the topic.\n",
    "\n",
    "<h4>What are your initial insights?</h4>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The initial insights of our project show that our hypothesis has some integrity. Although, there are still some ambiguities (such as inpatient/outpatient frequencies depending on the health care facility) in our data that need to be tied into our data exlporation.\n",
    "\n",
    "<h4>Are there any concrete results you can show at this point? If not, why not?</h4>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There are no concrete results other than numerical values on patient count over time. What our group has discovered is that the more funding a health facility obtains, the more equipment for patients. Although, once again, this does not mean the amount of workers decreased, but rather, better care for patients. This is also ambiguous data since we intended on having location being a factor of the analysis which could vary over the years.\n",
    "\n",
    "<h4>Going forward, what are the current biggest problems you’re facing?</h4>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Currently, the biggest issue facing our team is proving our hypothesis true. There is quite a bit of conflicting data that does not give us a statistically significant percent to show that the increase in funding is correlated to less workers needed and quicker inpatient/outpatient care.\n",
    "\n",
    "<h4>Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?</h4>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dedicating more time to interpreting results after data cleaning is a must for us. In terms of finishing the project and extracting meaningful results, we are on time to complete. \n",
    "\n",
    "<h4>Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?</h4>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Our project, compared to the other projects listed in class, is unique. We plan to stay with the project idea and continue the Data Exploratory Analysis process until we have concrete results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 8: Next Steps\n",
    "<h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What you plan to accomplish in the next month and how you plan to evaluate whether your project achieved the goals you set for it. \n",
    "</h4>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Our group plans to have the project fully completed by the time the deadline comes around. That entails having visualizations that any reader can understand, using statistical models to make a final judgement on the data we have collected so far, and finalizing our presentation for the class. We plan to evaluate our project mostly on the statistical models and ML visualization and Analysis to see if there are trends in which we can make conclusions. If we are unable to finish entirely, the data should be clean enough to make simple conjectures on our hypothesis to present. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
